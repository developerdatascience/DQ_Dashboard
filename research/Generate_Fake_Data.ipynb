{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837fac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/21 22:01:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import glob\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"faker\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94bf5ba0-ab7a-4485-b919-be9655222cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 22:02:04 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Initialize Faker for generating fake data\n",
    "fake = Faker()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the number of rows\n",
    "num_rows = 18000\n",
    "\n",
    "# Generate synthetic credit card fraud dataset\n",
    "data = {\n",
    "    \"TransactionID\": np.arange(1, num_rows + 1),\n",
    "    \"UserID\": np.random.randint(1000, 5000, size=num_rows),\n",
    "    \"TransactionAmount\": np.round(np.random.uniform(5, 5000, size=num_rows), 2),\n",
    "    \"TransactionDate\": pd.date_range(start=\"2024-01-01\", periods=num_rows, freq=\"T\"),\n",
    "    \"TransactionType\": np.random.choice([\"Online\", \"POS\", \"ATM Withdrawal\"], size=num_rows),\n",
    "    \"Merchant\": [fake.company() for _ in range(num_rows)],\n",
    "    \"Location\": [fake.city() for _ in range(num_rows)],\n",
    "    \"CardType\": np.random.choice([\"Visa\", \"MasterCard\", \"Amex\", \"Discover\"], size=num_rows),\n",
    "    \"IsFraud\": np.random.choice([0, 1], size=num_rows, p=[0.98, 0.02]),  # 2% fraud cases\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce missing values randomly\n",
    "for col in [\"TransactionAmount\", \"TransactionType\", \"Merchant\"]:\n",
    "    df.loc[df.sample(frac=0.03).index, col] = np.nan\n",
    "\n",
    "# Introduce duplicate rows\n",
    "df = pd.concat([df, df.sample(frac=0.04)], ignore_index=True)\n",
    "\n",
    "# Introduce inconsistent formats in the \"Location\" column\n",
    "df.loc[df.sample(frac=0.01).index, \"Location\"] = df[\"Location\"].apply(lambda x: x.lower())\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "filename = f\"{current_date}.csv\"\n",
    "\n",
    "# Save to CSV\n",
    "file_path = f\"../inputs/finance/{filename}\"\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "627cab1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20250219': 15601,\n",
       " '20250218': 18721,\n",
       " '20250220': 20401,\n",
       " '20250216': 31201,\n",
       " '20250217': 19761,\n",
       " '20250215': 41601,\n",
       " '20250214': 5201}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_records = {}\n",
    "for file in glob.glob(pathname=\"../archive/*.csv\"):\n",
    "    filename = file.split(\"/\")[2].split(\".\")[0]\n",
    "    count = spark.read.csv(file).count()\n",
    "    file_records[filename] = count\n",
    "\n",
    "file_records\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250220\n"
     ]
    }
   ],
   "source": [
    "yesterday = datetime.today() - timedelta(days=1)\n",
    "yesterday = yesterday.strftime(\"%Y%m%d\")\n",
    "print(yesterday)\n",
    "\n",
    "if Path(f\"../inputs/finance/{yesterday}.csv\").exists():\n",
    "    print(f\"{yesterday} exists\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path(f\"../inputs/finance/{current_date}\")\n",
    "\n",
    "if not folder_path.exists():\n",
    "    folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Folder {folder_path} created\")\n",
    "else:\n",
    "    print(f\"Folder {folder_path} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_move_file():\n",
    "    archive_path = Path(f\"archive/{yesterday}/\")\n",
    "\n",
    "    old_file_path = Path(f\"inputs/finance/{yesterday}.csv\")\n",
    "\n",
    "    if not archive_path.exists():\n",
    "        archive_path.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        print(f\"folder {archive_path} exists\")\n",
    "\n",
    "    if old_file_path.exists():\n",
    "        shutil.move(src=old_file_path, dst=archive_path)\n",
    "        print(\"file moved successfully\")\n",
    "    else:\n",
    "        print(\"Path does not exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b1893df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder ../archive/20250220 exists\n",
      "file moved successfully\n"
     ]
    }
   ],
   "source": [
    "# check for archive/20250220 path exist\n",
    "archive_path = Path(f\"../archive/{yesterday}/\")\n",
    "\n",
    "old_file_path = Path(f\"../inputs/finance/{yesterday}.csv\")\n",
    "\n",
    "if not archive_path.exists():\n",
    "    archive_path.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    print(f\"folder {archive_path} exists\")\n",
    "\n",
    "if old_file_path.exists():\n",
    "    shutil.move(src=old_file_path, dst=archive_path)\n",
    "    print(\"file moved successfully\")\n",
    "else:\n",
    "    print(\"Path does not exists\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56da786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250220 exists\n"
     ]
    }
   ],
   "source": [
    "if Path(f\"../inputs/finance/{yesterday}.csv\").exists():\n",
    "    print(f\"{yesterday} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a62f0bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>TransactionAmount</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>TransactionType</th>\n",
       "      <th>Merchant</th>\n",
       "      <th>Location</th>\n",
       "      <th>CardType</th>\n",
       "      <th>IsFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4174</td>\n",
       "      <td>3240.11</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>ATM Withdrawal</td>\n",
       "      <td>Brewer-Hamilton</td>\n",
       "      <td>New Lauratown</td>\n",
       "      <td>Visa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4507</td>\n",
       "      <td>2261.45</td>\n",
       "      <td>2024-01-01 00:01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Davis, Burton and Carson</td>\n",
       "      <td>East Crystal</td>\n",
       "      <td>Amex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-01 00:02:00</td>\n",
       "      <td>POS</td>\n",
       "      <td>Sheppard-Richardson</td>\n",
       "      <td>Lake Jaredtown</td>\n",
       "      <td>MasterCard</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2294</td>\n",
       "      <td>423.81</td>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "      <td>Online</td>\n",
       "      <td>Cook, Simmons and Hughes</td>\n",
       "      <td>New Ana</td>\n",
       "      <td>Visa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2130</td>\n",
       "      <td>1738.50</td>\n",
       "      <td>2024-01-01 00:04:00</td>\n",
       "      <td>ATM Withdrawal</td>\n",
       "      <td>Brown, Atkins and Levy</td>\n",
       "      <td>Lake Kayla</td>\n",
       "      <td>Amex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  UserID  TransactionAmount      TransactionDate  \\\n",
       "0              1    4174            3240.11  2024-01-01 00:00:00   \n",
       "1              2    4507            2261.45  2024-01-01 00:01:00   \n",
       "2              3    1860                NaN  2024-01-01 00:02:00   \n",
       "3              4    2294             423.81  2024-01-01 00:03:00   \n",
       "4              5    2130            1738.50  2024-01-01 00:04:00   \n",
       "\n",
       "  TransactionType                  Merchant        Location    CardType  \\\n",
       "0  ATM Withdrawal           Brewer-Hamilton   New Lauratown        Visa   \n",
       "1             NaN  Davis, Burton and Carson    East Crystal        Amex   \n",
       "2             POS       Sheppard-Richardson  Lake Jaredtown  MasterCard   \n",
       "3          Online  Cook, Simmons and Hughes         New Ana        Visa   \n",
       "4  ATM Withdrawal    Brown, Atkins and Levy      Lake Kayla        Amex   \n",
       "\n",
       "   IsFraud  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"../inputs/finance/20250221.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b83985",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = Path(f\"../inputs/finance/{yesterday}.csv\")\n",
    "destination_path = archive_path / f\"{yesterday}.csv\"\n",
    "\n",
    "if source_path.exists():\n",
    "    source_path.rename(destination_path)\n",
    "    print(f\"File moved to {destination_path}\")\n",
    "else:\n",
    "    print(f\"Source file {source_path} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1915d462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20250221'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.today().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8855a-126f-46d9-922e-dffc31d65f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d490874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key=\"AKIAWCHVIBUCJRMK5VHK\",\n",
    "aws_secret_access_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4a3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=\"\",\n",
    "    aws_secret_access_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1745aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.put_object(Bucket=\"creditcardfraudcontainer\", Key=\"bronze/credit_card_fraud.csv\", Body=\"../inputs/finance/credit_card_fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb043fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bucket in s3.list_buckets()[\"Buckets\"]:\n",
    "    print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.list_objects_v2(Bucket=\"creditcardfraudcontainer\")\n",
    "for obj in response.get(\"Contents\", []):\n",
    "    print(obj[\"Key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eaba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ffb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import logging\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Logger setup\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AWS_S3:\n",
    "    def __init__(self, bucketname: str, access_key: str, secret_key: str) -> None:\n",
    "        self.bucketname = bucketname\n",
    "        self.access_key = access_key\n",
    "        self.secret_key = secret_key\n",
    "\n",
    "        if not self.access_key or not self.secret_key:\n",
    "            logger.error(\"Please provide access and secret keys to continue\")\n",
    "            raise ValueError(\"Missing AWS credentials\")\n",
    "\n",
    "        if not self.bucketname:\n",
    "            logger.error(\"Please provide a valid bucket name\")\n",
    "            raise ValueError(\"Bucket name is required\")\n",
    "\n",
    "    def _connect_to_aws(self):\n",
    "        \"\"\"Create and return an S3 client\"\"\"\n",
    "        try:\n",
    "            s3 = boto3.client(\n",
    "                \"s3\",\n",
    "                aws_access_key_id=self.access_key,\n",
    "                aws_secret_access_key=self.secret_key\n",
    "            )\n",
    "            logger.info(\"Successfully connected to AWS S3\")\n",
    "            return s3  # ✅ RETURN the S3 client\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Connection failed: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    def upload_file_to_s3(self, s3_key: str, local_file_path: str) -> None:\n",
    "        \"\"\"Upload a file to S3\"\"\"\n",
    "        s3 = self._connect_to_aws()  # ✅ Fix: Get S3 client\n",
    "        \n",
    "        try:\n",
    "            with open(local_file_path, \"rb\") as file:\n",
    "                s3.put_object(Bucket=self.bucketname, Key=s3_key, Body=file)\n",
    "            logger.info(f\"File {local_file_path} uploaded successfully to S3 as {s3_key}\")\n",
    "        except Exception as e:\n",
    "            logger.error(\"File Upload Failed. Check credentials and permissions\")\n",
    "            raise e\n",
    "    \n",
    "    def read_small_data_from_s3(self, s3_key: str):\n",
    "        \"\"\"Read a small CSV file from S3\"\"\"\n",
    "        s3 = self._connect_to_aws()  # ✅ Fix: Get S3 client\n",
    "        \n",
    "        try:\n",
    "            obj = s3.get_object(Bucket=self.bucketname, Key=s3_key)  # ✅ Fix: Use `Key=`\n",
    "            df = pd.read_csv(StringIO(obj[\"Body\"].read().decode(\"utf-8\")))\n",
    "            logger.info(f\"Successfully read data from S3: {s3_key}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error occurred while reading data from AWS: {e}\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = AWS_S3(\n",
    "    bucketname=\"creditcardfraudcontainer\",\n",
    "    access_key=aws_access_key,\n",
    "    secret_key=aws_secret_access_key\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54249550",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.upload_file_to_s3(\n",
    "    s3_key=\"bronze/credit_card_fraud.csv\", \n",
    "    local_file_path='../inputs/finance/credit_card_fraud.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "local_path = os.path.abspath(\"../inputs/finance/credit_card_fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b581ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ETL-6mpoCg48",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
